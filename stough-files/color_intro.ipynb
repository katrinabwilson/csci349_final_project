{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color: Brightness, Hue, Saturation, Chromaticity\n",
    "stough 202-\n",
    "\n",
    "Here we'll explore a bit more about color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolor\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mcolor\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# For importing from alternative directory sources\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m  \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage.color as color\n",
    "\n",
    "# For importing from alternative directory sources\n",
    "import sys  \n",
    "sys.path.insert(0, '../dip_utils')\n",
    "\n",
    "from matrix_utils import arr_info\n",
    "from vis_utils import (vis_rgb_cube,\n",
    "                       vis_hsv_cube,\n",
    "                       vis_hists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision\n",
    "\n",
    "Color as light (as from displays or captured by cameras) is additive in nature. Humans (who can see) have [photoreceptor cells](https://en.wikipedia.org/wiki/Photoreceptor_cell), specialy-developed nerve cells called **rods** and **cones**. These cells are located in the retina, where light coming into the eye is focused. When you direct your vision somewhere, you are training the light toward your fovea, where the concentration of cones (4 to 7 million of them) is highest. The rods, on the periphery of vision, provide context and low-light vision. \n",
    "\n",
    "<img src=\"../dip_figs/eyeball.png\" style=\"height:300px;\"/><img src=\"../dip_figs/rod_cone_density.png\" style=\"height:300px;\"/>\n",
    "\n",
    "Further, the cones are split into three types, red, green, and blue, based on their absorption characteristics. This is how we percieve color, based on the differential stimulation of these three kinds of color-receptive cones to light within the visible spectrum.\n",
    "\n",
    "<img src=\"../dip_figs/cone_absorption.png\" style=\"height:300px;\"/>\n",
    "\n",
    "Displays work by blending just three relatively pure red, green, and blue light sources in each pixel. So an image is actually three images or channels, representing the red, green, and blue component images. The [matplotlib tutorial](matplotlib_tutorial.ipynb) shows a nice example of this. When you watch a video you're actually being exposed to individual frames at such a high frequency (24 typically, 30, 60, or even 120 frames per second) that [you perceive motion](https://youtu.be/3BJU2drrtCM).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brightness\n",
    "\n",
    "We use achromatic **Intensity** as our measure of brightness. The most common current display technology, and matplotlib, uses 8-bit color depth or quantization. White light is an equal combination of the R,G,B signals, leaving us with just 8 bits to represent all grayscale values, $[0,255]$. Regardless of how many gradations (discrete monotonically increasing values) we provide, the display will end up the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m6\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[1;32m      2\u001b[0m plt\u001b[39m.\u001b[39mimshow(np\u001b[39m.\u001b[39mtile(np\u001b[39m.\u001b[39marange(\u001b[39m256\u001b[39m), (\u001b[39m25\u001b[39m,\u001b[39m1\u001b[39m)), cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(6,1))\n",
    "plt.imshow(np.tile(np.arange(256), (25,1)), cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brightness: more doesn't help.\n",
    "plt.figure(figsize=(6,1))\n",
    "plt.imshow(np.tile(np.arange(1024), (100,1)), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above I show a linear grayscale in 256 and 1024 gradations, resulting in identical images due to the display's and matplotlib's default 8-bit depth. With the advent of High Dynamic Range (HDR) displays and cameras, more gradations will be possible, allowing for a greater color gamut as well. See more [here](https://codecalamity.com/hdr-hdr10-hdr10-hlg-and-dolby-vision/) and [here](https://youtu.be/Lt75d5sZwZA).\n",
    "There is also the possibility of working with HDR images through [OpenCV](https://docs.opencv.org/3.4/d2/df0/tutorial_py_hdr.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB Color\n",
    "\n",
    "With 8-bit color depth in each of the red, green, and blue channels, there are $2^{24}\\sim16.8M$ possible colors. I've written a couple of visualization tools to think about what colors are in any particular image. One is a histogram while the other visualizes the 3D Color cube. Let's take a look! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dip_pics/sf.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m I \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39;49mimread(\u001b[39m'\u001b[39;49m\u001b[39m../dip_pics/sf.jpg\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/csci349/lib/python3.10/site-packages/matplotlib/pyplot.py:2389\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2385\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mimread)\n\u001b[1;32m   2386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimread\u001b[39m(\n\u001b[1;32m   2387\u001b[0m         fname: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m pathlib\u001b[39m.\u001b[39mPath \u001b[39m|\u001b[39m BinaryIO, \u001b[39mformat\u001b[39m: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2388\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m-> 2389\u001b[0m     \u001b[39mreturn\u001b[39;00m matplotlib\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mimread(fname, \u001b[39mformat\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/csci349/lib/python3.10/site-packages/matplotlib/image.py:1525\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(parse\u001b[39m.\u001b[39murlparse(fname)\u001b[39m.\u001b[39mscheme) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1519\u001b[0m     \u001b[39m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[1;32m   1520\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1521\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease open the URL for reading and pass the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1522\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresult to Pillow, e.g. with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1523\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1524\u001b[0m         )\n\u001b[0;32m-> 1525\u001b[0m \u001b[39mwith\u001b[39;00m img_open(fname) \u001b[39mas\u001b[39;00m image:\n\u001b[1;32m   1526\u001b[0m     \u001b[39mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[1;32m   1527\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(image, PIL\u001b[39m.\u001b[39mPngImagePlugin\u001b[39m.\u001b[39mPngImageFile) \u001b[39melse\u001b[39;00m\n\u001b[1;32m   1528\u001b[0m             pil_to_array(image))\n",
      "File \u001b[0;32m~/anaconda3/envs/csci349/lib/python3.10/site-packages/PIL/Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3244\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[1;32m   3246\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[0;32m-> 3247\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   3248\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   3250\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dip_pics/sf.jpg'"
     ]
    }
   ],
   "source": [
    "I = plt.imread('../dip_pics/sf.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_hists(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_rgb_cube(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RGB plot shows each pixel's position in x,y,z equivalent to the R,G,B channels, while also coloring the pixel according to that R,G,B. That is, the origin $(0,0,0)$ is black, as it consists of zero intensity in any of the three color channels, while the point $(255,255,255)$ is completely white. The achromatic intensity scale can be seen as the diagonal connecting these points, while the points $(255,0,0)$, $(0,255,0)$, and $(0,0,255)$ show as the primary colors red, green, and blue. The other three corners of the cube represent the secondary colors of yellow, magenta, and cyan.\n",
    "\n",
    "If we uniformly randomly sample the entire octant, this visualization can show us the color cube in 3D as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random((100,100,3))\n",
    "\n",
    "# X = np.random.randn(100,100,3)\n",
    "# X = (X-X.min())/(X.max()-X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_rgb_cube(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hue and Saturation (and Value/Intensity)\n",
    "All the colors of the rainbow! **Hue** is generally what we think of as color. <span style=\"color:#33FF33\">**Bold colors**</span> versus  <span style=\"color:#bbFFbb\">**muted or pastels**</span> differ in what is called **Saturation**, or the level of purity of the hue/color. Here is a plot of all fully saturated colors then, thanks to this [stackoverflow answer](https://stackoverflow.com/questions/10787103/2d-hsv-color-space-in-matplotlib). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, H = np.mgrid[0:1:100j, 0:1:360j]\n",
    "S = np.ones_like(V)\n",
    "HSV = np.dstack((H,S,V))\n",
    "RGB = color.hsv2rgb(HSV)\n",
    "plt.figure(figsize=(6,2))\n",
    "plt.imshow(RGB, origin='lower')\n",
    "plt.xlabel('H') # These don't need to change\n",
    "plt.ylabel('V')\n",
    "plt.title('$S_{HSV}=1$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The y-axis in the above plot is all that's left of our perception of color if you take out hue and saturation; that is, intensity or **Value**. \n",
    "\n",
    "One thing you'll notice in the above plot is that red shows up on both the left and right-hand sides. That's because this HSV space is thought of as circular. \n",
    "\n",
    "Let's try to show this circular nature of hues for some particular saturation and value. Here I'm creating 10K h,s,v triples where saturationa nd value are held constant while the hue is sampled linearly, converting them to r,g,b, and then displaying them in both the HSV and RGB cube spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = np.stack([np.linspace(0,1,10000), \n",
    "                .8*np.ones(10000),\n",
    "                .8*np.ones(10000)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = color.hsv2rgb(hsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_hsv_cube(np.reshape(rgb, (100,100,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_rgb_cube(np.reshape(rgb, (100,100,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we uniformly randomly sample the entire RGB space again, we can see the entire HSV colorspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_hsv_cube(np.random.random((100,100,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See more in the [HSV tutorial](color_HSV.ipynb). \n",
    "\n",
    "At this point we've observed two ways of thinking about color. Either as red, green, and blue stimuli for our vision, or potentially a more intuitive understanding of color as hue, saturation, and value. There are still other colorspaces that are very useful in digital image processing, including [YCbCr](./color_YCbCr.ipynb) and [L\\*a\\*b\\*](./color_Lab.ipynb). Take a look at those demos next.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci349",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c6b589b067a5e34579d6f85fe9610ad26214f5ea75d09a5546da43ea32d8b57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
